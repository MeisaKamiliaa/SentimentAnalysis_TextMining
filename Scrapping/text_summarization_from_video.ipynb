{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steam\\OneDrive\\Desktop\\Coding Kuliah\\Python\\Text Mining\\.env\\TextMining\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coursera Review Our Experience and How it Works</td>\n",
       "      <td>what do we think about Corsair we say it's one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coursera Review  My Thoughts After 5 Years and...</td>\n",
       "      <td>so I've mentioned Coursera in a handful of my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Top 5 Online Learning Platforms 2024  Review o...</td>\n",
       "      <td>if you want to study something new but don't h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coursera Review The Best Elearning Site</td>\n",
       "      <td>hey guys Lewis here and in today's video I wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Palo Alto Networks Cybersecurity Professional ...</td>\n",
       "      <td>what's going on guys it's Moda same here and t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0    Coursera Review Our Experience and How it Works   \n",
       "1  Coursera Review  My Thoughts After 5 Years and...   \n",
       "2  Top 5 Online Learning Platforms 2024  Review o...   \n",
       "3            Coursera Review The Best Elearning Site   \n",
       "4  Palo Alto Networks Cybersecurity Professional ...   \n",
       "\n",
       "                                            raw_text  \n",
       "0  what do we think about Corsair we say it's one...  \n",
       "1  so I've mentioned Coursera in a handful of my ...  \n",
       "2  if you want to study something new but don't h...  \n",
       "3  hey guys Lewis here and in today's video I wan...  \n",
       "4  what's going on guys it's Moda same here and t...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = pd.read_csv('../Data/rawtext.tsv', sep='\\t')\n",
    "raw_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_text = []\n",
    "drop_index = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steam\\OneDrive\\Desktop\\Coding Kuliah\\Python\\Text Mining\\.env\\TextMining\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text at 0 has been summarized\n",
      "Text at 1 has been summarized\n",
      "Text at 2 has been summarized\n",
      "Text at 3 has been summarized\n",
      "Text at 4 has been summarized\n",
      "Text at 5 has been summarized\n",
      "Text at 6 has been summarized\n",
      "Text at 7 has been summarized\n",
      "Text at 8 has been summarized\n",
      "Text at 9 has been summarized\n",
      "Text at 10 has been summarized\n",
      "Text at 11 has been summarized\n",
      "Text at 12 has been summarized\n",
      "Text at 13 has been summarized\n",
      "Text at 14 has been summarized\n",
      "Text at 15 has been summarized\n",
      "Text at 16 has been summarized\n",
      "Text at 17 has been summarized\n",
      "Text at 18 has been summarized\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "for i in range(len(raw_text)):\n",
    "\n",
    "    text = raw_text['raw_text'][i]\n",
    "\n",
    "    if (text is np.nan):\n",
    "        print(f'Text is not available at index {i}')\n",
    "        drop_index.append(i)\n",
    "        continue\n",
    "\n",
    "    inputs = tokenizer(text, max_length=1024, return_tensors='pt', truncation=True)\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=30, do_sample=False)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    summarized_text.append(summary)\n",
    "    print(f'Text at {i} has been summarized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_data = pd.DataFrame({'title': raw_text['title']})\n",
    "summarized_data = summarized_data.drop(index=drop_index)\n",
    "summarized_data['summarized text'] = summarized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_data.to_csv('../Data/SummarizedDataVideo.tsv', index=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
